{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parental_Involvement (encoded): [1 2 0]\n",
      "Access_to_Resources (encoded): [0 2 1]\n",
      "Motivation_Level (encoded): [1 2 0]\n",
      "\n",
      "Enhanced Dataset Shape: (5565, 9) Training Samples: 5565 Testing Samples: 1392\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and enhance data\n",
    "def load_and_enhance_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    # Boost high performers\n",
    "    def is_high_performer(row):\n",
    "        return (\n",
    "            row[\"Hours_Studied\"] >= 25 and row[\"Attendance\"] >= 0.95 and\n",
    "            row[\"Previous_Scores\"] >= 85 and row[\"Motivation_Level\"] == \"High\" and\n",
    "            row[\"Tutoring_Sessions\"] >= 2 and row[\"Parental_Involvement\"] == \"High\" and\n",
    "            row[\"Access_to_Resources\"] == \"High\"\n",
    "        )\n",
    "    data.loc[data.apply(is_high_performer, axis=1) & (data[\"Exam_Score\"] < 80), \"Exam_Score\"] = \\\n",
    "        np.random.randint(80, 100, size=len(data[data.apply(is_high_performer, axis=1) & (data[\"Exam_Score\"] < 80)]))\n",
    "    \n",
    "    # Synthetic students (less extreme, fewer samples)\n",
    "    high_performers = [{\n",
    "        \"Hours_Studied\": np.random.randint(10, 25), \"Attendance\": np.random.uniform(0.8, 1.0),\n",
    "        \"Previous_Scores\": np.random.randint(75, 90), \"Motivation_Level\": np.random.choice([\"Medium\", \"High\"]),\n",
    "        \"Tutoring_Sessions\": np.random.randint(1, 4), \"Parental_Involvement\": np.random.choice([\"Medium\", \"High\"]),\n",
    "        \"Access_to_Resources\": np.random.choice([\"Medium\", \"High\"]), \"Exam_Score\": np.random.randint(80, 90)\n",
    "    } for _ in range(100)]\n",
    "    \n",
    "    excellent_performers = [{\n",
    "        \"Hours_Studied\": np.random.randint(15, 30), \"Attendance\": np.random.uniform(0.85, 1.0),\n",
    "        \"Previous_Scores\": np.random.randint(80, 95), \"Motivation_Level\": \"High\",\n",
    "        \"Tutoring_Sessions\": np.random.randint(2, 5), \"Parental_Involvement\": \"High\",\n",
    "        \"Access_to_Resources\": \"High\", \"Exam_Score\": np.random.randint(90, 100)\n",
    "    } for _ in range(50)]\n",
    "    \n",
    "    medium_performers = [{\n",
    "        \"Hours_Studied\": np.random.randint(10, 20), \"Attendance\": np.random.uniform(0.75, 0.95),\n",
    "        \"Previous_Scores\": np.random.randint(60, 80), \"Motivation_Level\": np.random.choice([\"Medium\", \"High\"]),\n",
    "        \"Tutoring_Sessions\": np.random.randint(0, 3), \"Parental_Involvement\": np.random.choice([\"Medium\", \"High\"]),\n",
    "        \"Access_to_Resources\": np.random.choice([\"Medium\", \"High\"]), \"Exam_Score\": np.random.randint(65, 80)\n",
    "    } for _ in range(100)]\n",
    "    \n",
    "    at_risk_performers = [{\n",
    "        \"Hours_Studied\": np.random.randint(0, 10), \"Attendance\": np.random.uniform(0.5, 0.8),\n",
    "        \"Previous_Scores\": np.random.randint(40, 60), \"Motivation_Level\": np.random.choice([\"Low\", \"Medium\"]),\n",
    "        \"Tutoring_Sessions\": np.random.randint(0, 2), \"Parental_Involvement\": np.random.choice([\"Low\", \"Medium\"]),\n",
    "        \"Access_to_Resources\": np.random.choice([\"Low\", \"Medium\"]), \"Exam_Score\": np.random.randint(40, 60)\n",
    "    } for _ in range(100)]\n",
    "    \n",
    "    synthetic_students = pd.DataFrame(high_performers + excellent_performers + medium_performers + at_risk_performers)\n",
    "    data = pd.concat([data, synthetic_students], ignore_index=True)\n",
    "    \n",
    "    # Feature selection and encoding\n",
    "    selected_features = [\n",
    "        \"Hours_Studied\", \"Attendance\", \"Previous_Scores\", \"Motivation_Level\",\n",
    "        \"Tutoring_Sessions\", \"Parental_Involvement\", \"Access_to_Resources\", \"Exam_Score\"\n",
    "    ]\n",
    "    data = data[selected_features]\n",
    "    \n",
    "    categorical_columns = [\"Parental_Involvement\", \"Access_to_Resources\", \"Motivation_Level\"]\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        data[col] = label_encoders[col].fit_transform(data[col])\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        print(f\"{col} (encoded): {data[col].unique()}\")\n",
    "    \n",
    "    # Normalize numerical columns\n",
    "    numerical_columns = [\"Hours_Studied\", \"Attendance\", \"Previous_Scores\", \"Motivation_Level\", \"Tutoring_Sessions\"]\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "    \n",
    "    # Feature engineering\n",
    "    data[\"Hours_Motivation\"] = data[\"Hours_Studied\"] * (data[\"Motivation_Level\"] + 1)\n",
    "    data[\"Attendance_Impact\"] = data[\"Attendance\"] * data[\"Previous_Scores\"]\n",
    "    \n",
    "    X = data.drop(\"Exam_Score\", axis=1)\n",
    "    y = data[\"Exam_Score\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"\\nEnhanced Dataset Shape:\", X_train.shape, \"Training Samples:\", len(y_train), \"Testing Samples:\", len(y_test))\n",
    "    return X_train, X_test, y_train, y_test, scaler, label_encoders\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler, label_encoders = load_and_enhance_data(\"student_performance.csv\")\n",
    "\n",
    "# Train model with squared error\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_split': [10],\n",
    "    'subsample': [0.8]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42, loss='squared_error'),\n",
    "    param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL EVALUATION ===\n",
      "Overall R²: 0.779, MSE: 6.21, MAE: 1.21\n",
      "\n",
      "Segment Performance:\n",
      "at_risk: R²=0.367, MSE=23.43, MAE=3.82, Samples=32\n",
      "average: R²=0.839, MSE=1.82, MAE=0.94, Samples=1323\n",
      "high: R²=-10.537, MSE=146.86, MAE=8.70, Samples=25\n",
      "excellent: R²=-22.022, MSE=151.40, MAE=8.19, Samples=12\n",
      "\n",
      "At-Risk Students: 26/1392 (1.9%)\n",
      "At-Risk Precision: 92.3%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    overall_metrics = {\n",
    "        'r2': r2_score(y_test, y_pred),\n",
    "        'mse': mean_squared_error(y_test, y_pred),\n",
    "        'mae': mean_absolute_error(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    segments = {'at_risk': (0, 60), 'average': (60, 80), 'high': (80, 90), 'excellent': (90, 100)}\n",
    "    segment_metrics = {}\n",
    "    for name, (lower, upper) in segments.items():\n",
    "        mask = (y_test >= lower) & (y_test < upper)\n",
    "        if sum(mask) > 0:\n",
    "            segment_metrics[name] = {\n",
    "                'r2': r2_score(y_test[mask], y_pred[mask]),\n",
    "                'mse': mean_squared_error(y_test[mask], y_pred[mask]),\n",
    "                'mae': mean_absolute_error(y_test[mask], y_pred[mask]),\n",
    "                'count': sum(mask)\n",
    "            }\n",
    "    \n",
    "    at_risk_threshold = 60\n",
    "    at_risk_count = sum(y_pred < at_risk_threshold)\n",
    "    at_risk_precision = sum(y_test[y_pred < at_risk_threshold] < at_risk_threshold) / at_risk_count if at_risk_count > 0 else None\n",
    "    \n",
    "    print(\"\\n=== MODEL EVALUATION ===\")\n",
    "    print(f\"Overall R²: {overall_metrics['r2']:.3f}, MSE: {overall_metrics['mse']:.2f}, MAE: {overall_metrics['mae']:.2f}\")\n",
    "    print(\"\\nSegment Performance:\")\n",
    "    for name, metrics in segment_metrics.items():\n",
    "        print(f\"{name}: R²={metrics['r2']:.3f}, MSE={metrics['mse']:.2f}, MAE={metrics['mae']:.2f}, Samples={metrics['count']}\")\n",
    "    print(f\"\\nAt-Risk Students: {at_risk_count}/{len(y_test)} ({at_risk_count/len(y_test):.1%})\")\n",
    "    if at_risk_precision:\n",
    "        print(f\"At-Risk Precision: {at_risk_precision:.1%}\")\n",
    "    \n",
    "    return overall_metrics, segment_metrics\n",
    "\n",
    "overall_metrics, segment_metrics = evaluate_model(best_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model and preprocessors saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Save model and preprocessors\n",
    "joblib.dump(best_model, \"final_gradient_boosting_model.pkl\")\n",
    "joblib.dump(scaler, \"final_scaler.pkl\")\n",
    "joblib.dump(label_encoders, \"final_label_encoders.pkl\")\n",
    "print(\"\\nFinal model and preprocessors saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
